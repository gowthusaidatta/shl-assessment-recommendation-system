
# SHL Assessment Recommendation System (GenAI + RAG)

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A production-oriented, Retrieval-Augmented Generation (RAG) system for recommending **SHL Individual Test Solutions** based on natural language queries or job descriptions.



## ğŸ¯ Overview

This system addresses the challenge of identifying the most relevant SHL assessments for a given role using semantic retrieval and structured reranking.

**Key highlights:**
- Crawled **377 Individual Test Solutions** from SHLâ€™s public product catalog
- Semantic retrieval using FAISS and sentence embeddings
- Query understanding with skill and test-type inference
- Balanced recommendations across **Knowledge/Skills** and **Personality/Behavior**
- REST API compliant with SHL specification
- Quantitative evaluation using **Mean Recall@10**
- Lightweight Streamlit frontend for manual validation



## ğŸ§  System Capabilities

- Accepts:
  - Natural language queries
  - Job description text
- Returns:
  - 5â€“10 relevant SHL Individual Test Solutions
  - Balanced mix of technical and behavioral assessments where applicable



## ğŸ§© Architecture


Input Query / JD
â†“
LLM Query Analysis (Gemini) - skill extraction
â†“
Sentence Embedding (all-MiniLM-L6-v2)
â†“
FAISS Vector Search (Top-N candidates)
â†“
LLM Reranking (Gemini, optional)
â†“
Rule-based Balancing & Test-Type Distribution
â†“
Final Ranked Recommendations (Top-10)


## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.11
- **Backend:** FastAPI
- **Embeddings:** Sentence-Transformers (all-MiniLM-L6-v2)
- **Vector Store:** FAISS
- **LLM:** Google Gemini Pro (query understanding + reranking)
- **Frontend:** Streamlit
- **Evaluation:** Mean Recall@10 (custom implementation)

## ğŸ“¦ Data Collection

- **Source:** https://www.shl.com/solutions/products/product-catalog/
- Only **Individual Test Solutions** were collected
- Pre-packaged Job Solutions were explicitly excluded
- Total assessments indexed: **377**
  - Knowledge & Skills assessments
  - Personality & Behavioral assessments

All data ingestion is performed via a reproducible crawling pipeline.

## ğŸ“¡ API Endpoints

### Health Check

GET /health

### Recommendation Endpoint

POST /recommend

**Request**
json
{
  "query": "Hiring a Java developer with strong collaboration skills"
}

**Response**
json
{
  "query": "...",
  "recommendations": [
    {
      "assessment_name": "...",
      "url": "...",
      "test_type": "...",
      "duration": "...",
      "remote_support": true,
      "adaptive_support": false
    }
  ]
}

The API strictly adheres to the response schema required in the assignment specification.

## ğŸš€ Quick Start (Local)

bash
# Activate virtual environment
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Optional: rebuild pipeline artifacts
python scripts/01_crawl_catalog.py
python scripts/02_build_embeddings.py
python scripts/03_evaluate_train_set.py
python scripts/04_generate_test_predictions.py

# Run API
uvicorn src.api.app:app --reload

# Run frontend (separate terminal)
streamlit run src/frontend/app.py

## ğŸ“Š Evaluation

* **Metric:** Mean Recall@10
* **Dataset:** Provided labeled training queries
* **Methodology:**

  * Baseline: pure embedding-based retrieval
  * Improved: reranking with skill overlap and test-type balancing

Evaluation was used iteratively to refine retrieval quality and recommendation balance.
Detailed results and analysis are documented in the technical report.

## ğŸ“ Project Structure
.
â”œâ”€â”€ config/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ ranking/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ scripts/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ predictions/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TECHNICAL_REPORT.md
â”‚   â””â”€â”€ DEPLOYMENT.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ“„ Deliverables

* âœ… REST API with `/health` and `/recommend`
* âœ… Streamlit-based frontend
* âœ… CSV predictions for test set (`gowthu_manikanta.csv`)
* âœ… Technical design and evaluation report (2-page PDF)
* âœ… Fully reproducible codebase with LLM integration
* âœ… Deployment-ready (Procfile + runtime.txt)


## ğŸš€ Deployment

### Quick Deploy to Railway (Recommended)

1. Push to GitHub (already done âœ…)
2. Go to https://railway.app
3. New Project â†’ Deploy from GitHub
4. Select `shl-assessment-recommendation-system`
5. Railway auto-deploys in ~3 minutes

Your API will be live at: `https://your-app.railway.app`

See [docs/GITHUB_DEPLOYMENT.md](docs/GITHUB_DEPLOYMENT.md) for detailed instructions.

### Alternative Platforms
- **Render:** Free tier, auto-deploys from GitHub
- **Google Cloud Run:** Serverless, free tier available
- **Docker:** See [docs/GITHUB_DEPLOYMENT.md](docs/GITHUB_DEPLOYMENT.md) for Dockerfile

---

## ğŸ“Š Submission Files

- **Predictions CSV:** `data/predictions/gowthu_manikanta.csv` (9 queries, 89 recommendations)
- **Technical Report:** `docs/TECHNICAL_REPORT_2PAGE.md` (convert to PDF for submission)
- **GitHub Repository:** https://github.com/gowthusaidatta/shl-assessment-recommendation-system
- **API Endpoints:** Deploy and share live URL
- **Frontend:** Deploy Streamlit and share live URL

---

## ğŸ‘¤ Author

**Gowthu V V Satya Sai Datta Manikanta**  
SHL AI Research Intern - Take-Home Assessment  
December 2025

